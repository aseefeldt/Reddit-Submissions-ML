{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b69695e-b5d7-4353-9668-633ce2399437",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e7b88b-2ac3-4ac9-b3b4-844ee45871ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import praw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e376ad-2135-4427-923e-9e0d5a73ef03",
   "metadata": {},
   "source": [
    "## Removing Scientific Notation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d0369fcd-3990-4cd3-bc3d-738e65ac2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa57fa-8972-4902-9830-8e60c343d32d",
   "metadata": {},
   "source": [
    "## Setting up the Praw API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d196aa81-f402-409b-802c-9ed8257e42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id= \"a953DGqYYRWq7MIJt04srw\",\n",
    "    client_secret= \"Gj_aZBxPj22zKHL3JLm1PvTqAr6i2Q\",\n",
    "    user_agent=\"jupityer:swap (by u/Hour-Librarian940)\",\n",
    "    username = \"Hour-Librarian940\",\n",
    "    password = \"_?nD#huS_GQWz6A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8432e664-b634-4ddf-b4a9-a3ed71255564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(reddit.read_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda20b78-890a-46a6-a195-cb298d5bf2f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pulling from the Costa Rica Sub (tico) \n",
    "Pulling top 1000 from four reddit categories.  I pulled the info this way as reddit stopped allowing time based pulls with 'before' or 'after'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d77b6b0e-9503-4a53-900d-87d4d9353f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "sub = reddit.subreddit(\"CostaRica\")\n",
    "posts = [\n",
    "    list(sub.new(limit=1000)), \n",
    "    list(sub.hot(limit=1000)), \n",
    "    list(sub.controversial(limit=1000)),\n",
    "    list(sub.top(limit=1000))\n",
    "]\n",
    "for l in posts:\n",
    "    for post in l:\n",
    "        data.append([post.title, post.selftext, post.subreddit]) \n",
    "df_tico = pd.DataFrame(data, columns =['title', 'self_text', 'subreddit'])\n",
    "df_tico.drop_duplicates(inplace = True)\n",
    "df_tico.to_csv('../datasets/subtico.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447b663-fc9a-4936-a56c-c49258fd3fce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pulling from the Costa Rica Travel Sub (tourist) \n",
    "Pulling top 1000 from four reddit categories.  I pulled the info this way as reddit stopped allowing time based pulls with 'before' or 'after'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4cececba-86b9-4c2d-9a49-1e0e5461a10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = reddit.subreddit(\"CostaRicaTravel\")\n",
    "data_tour = []\n",
    "posts = [\n",
    "    list(sub.new(limit=1000)), \n",
    "    list(sub.hot(limit=1000)), \n",
    "    list(sub.controversial(limit=1000)),\n",
    "    list(sub.top(limit=1000))\n",
    "]\n",
    "for l in posts:\n",
    "    for post in l:\n",
    "        data_tour.append([post.title, post.selftext, post.subreddit]) \n",
    "df_tourist = pd.DataFrame(data_tour, columns =['title', 'self_text', 'subreddit'])\n",
    "df_tourist.drop_duplicates(inplace = True)\n",
    "df_tourist.to_csv('../datasets/subtourist.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a80188-004e-46b3-90a5-5aa26f44ec4c",
   "metadata": {},
   "source": [
    "## Adjusting Datasets \n",
    "When exporting, some values in 'self-text' become NAN.  It appears these are the automatic ads.  We will remove the NAN from each data set, and an additional 600 from the tico set so that we have an equal number of values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e18087-9dcf-42b2-9572-40da6f9cb691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tico = pd.read_csv('../datasets/subtico.csv', encoding='utf-8')\n",
    "df_tourist = pd.read_csv('../datasets/subtourist.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5114d798-a97e-4de4-898e-a6f5dc42d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tico.dropna(inplace=True)\n",
    "df_tourist.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410136b-43df-444c-821b-a5ace524e60f",
   "metadata": {},
   "source": [
    "## Combining Datasets\n",
    "It appears that some posts were put on both pages, so dropping those as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664c34b8-773c-48ce-9d68-05627accd78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3408, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_tico, df_tourist]) \n",
    "#df.drop_duplicates(inplace= True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b7b07-2bec-4f32-960b-b80ae6440852",
   "metadata": {},
   "source": [
    "## Exporting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f40a33-cf39-4f1f-9504-7efb74237af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/subs.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4608b3-a403-4ade-b1d4-4691319544f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
